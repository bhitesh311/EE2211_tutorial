{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bj2U54EFEoX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy.linalg import inv\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1 a) with bias"
      ],
      "metadata": {
        "id": "C5J35EXTK8SH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x=np.array([[1,-10],[1,-8],[1,-3],[1,-1],[1,2],[1,8]])\n",
        "y=np.array([[5],[5],[4],[3],[2],[2]])\n",
        "w=inv(x.T @ x)@(x.T)@(y)\n",
        "print(w)\n",
        "\n",
        "#linear regression\n",
        "#y_line = x @ w\n",
        "y_line=x.dot(w)\n",
        "print(y_line)\n",
        "\n",
        "#x_line = np.linspace(x[:, 1].min(), x[:, 1].max(), 100)  # Generate 100 points for the line\n",
        "#y_line_cont = w[0] + w[1] * x_line # y = mx+c\n",
        "\n",
        "\n",
        "\n",
        "plt.scatter(x[:,1],y,label=' training samples')\n",
        "plt.plot(x[:,1],y_line,color='orange',label='linear regression')\n",
        "#plt.plot(x_line,y_line_cont,color='orange',label='linear regression')\n",
        "plt.grid(True)  # Display grid\n",
        "\n",
        "\n",
        "# Highlight X and Y axes separately\n",
        "plt.axhline(y=0, color='black', linewidth=1.5)  # X-axis (horizontal line)\n",
        "plt.axvline(x=0, color='black', linewidth=1.5)  # Y-axis (vertical line)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "ztKst9eUK7UX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1 b) without bias"
      ],
      "metadata": {
        "id": "z1T4yVNWMqOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=np.array([[-10],[-8],[-3],[-1],[2],[8]])\n",
        "y=np.array([[5],[5],[4],[3],[2],[2]])\n",
        "\n",
        "w=inv(x.T @ x)@(x.T)@(y)\n",
        "print(w)\n",
        "\n",
        "#linear regression\n",
        "y_line = x @ w\n",
        "print(y_line)\n",
        "\n",
        "#x_line = np.linspace(x[:,].min(), x[:,].max(), 100)  # Generate 100 points for the line\n",
        "#y_line_cont = w[0] * x_line # y = mx\n",
        "\n",
        "\n",
        "\n",
        "plt.scatter(x,y,label=' training samples')\n",
        "#plt.plot(x_line,y_line_cont,color='orange',label='linear regression w/o bias')\n",
        "plt.plot(x,y_line,color='orange',label='linear regression w/o bias')\n",
        "plt.grid(True)  # Display grid\n",
        "\n",
        "# Display grid\n",
        "plt.grid(True, linestyle='--', linewidth=0.5)\n",
        "\n",
        "# Highlight X and Y axes separately\n",
        "plt.axhline(y=0, color='black', linewidth=1.5)  # X-axis (horizontal line)\n",
        "plt.axvline(x=0, color='black', linewidth=1.5)  # Y-axis (vertical line)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "HQ47iFgbMpXw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}